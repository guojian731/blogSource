---
title: 每日一问-数据结构类
date: 2018-07-14 14:57:52
tags: 每日一问
---

### HashMap问题 ###

**Q：为什么HashMap的容量必须为2的n次方。**

***A：***

``` java 
static int indexFor(int h, int length) {
        // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2";
        return h & (length-1);
    }
```
与运算：
运算规则：0&0=0;0&1=0;1&0=0;1&1=1;
即：两位同时为“1”，结果才为“1”，否则为0；
hashMap是根据key的hashCode值进行处理之后的hash值，根据这个hash值来判断放入哪个槽里。为了数据可以均匀分布，我们一般都是取余，但是在计算机中取余的速度并没有与运算效率高,所以hashMap使用的是与运算，源码如下。2的n次方-1的二进制都是"1","11","111",再进行与运算的时候数据可以均匀分布。我们分别将hash值设置0~20，map的容量分别设置为8和10，当length=8的时候为2的n次方为8的时候，数据排列是均匀的；当length等于10的时候，数组中下标为0，1，8，9存了很多的值，而其他的没有值，造成了数据严重的不均匀。

``` java 

public static void main(String[] args) {
        int length=8;
       for (int hash=0;hash<20;hash++){
           System.out.println("hash值："+hash  +";与的值"+(hash & (length-1)));
       }
    }

```

length=8：

``` java 

hash值：0;与的值0
hash值：1;与的值1
hash值：2;与的值2
hash值：3;与的值3
hash值：4;与的值4
hash值：5;与的值5
hash值：6;与的值6
hash值：7;与的值7
hash值：8;与的值0
hash值：9;与的值1
hash值：10;与的值2
hash值：11;与的值3
hash值：12;与的值4
hash值：13;与的值5
hash值：14;与的值6
hash值：15;与的值7
hash值：16;与的值0
hash值：17;与的值1
hash值：18;与的值2
hash值：19;与的值3

```


length=10:

```

hash值：0;与的值0
hash值：1;与的值1
hash值：2;与的值0
hash值：3;与的值1
hash值：4;与的值0
hash值：5;与的值1
hash值：6;与的值0
hash值：7;与的值1
hash值：8;与的值8
hash值：9;与的值9
hash值：10;与的值8
hash值：11;与的值9
hash值：12;与的值8
hash值：13;与的值9
hash值：14;与的值8
hash值：15;与的值9
hash值：16;与的值0
hash值：17;与的值1
hash值：18;与的值0
hash值：19;与的值1

```

**Q：hashMap的key值可以为null吗？**

***A：***可以，hashmap中判断key是否为null，如果为null，在为0的数组中，遍历链表，查找是否存在key值是有为null，有替换value，没有加上。

**Q:hashMap（jdk1.7）数据量大的时候为什么效率不高？**

***A：***因为当数据量庞大的时候，容量到了极限就无法扩容，导致数组中的链表长度过长，在put和get的时候需要遍历该下标下的所有链表并进行判断。

**Q:hashMap在1.8进行了哪些优化**

***A：***
- hash的算法上，获取key的hash值更加随机，并且在扩容上更有优势。

- 数据结构上来说
1.7：是一个数组加链表的组合。
1.8：是一个数组+链表+红黑树的组合，当链表长度<=8的时候，依旧是使用数组，当链表长度>8的时候，链表变成红黑树，这样容易数据的查找。

- 存储值的顺序上
1.7：冲突的hash值会放在链表的头上，因为工程师认为新的key值用到的几率更大。
1.8：冲突的hash值会放在链表的尾上(链表的长度是8以内，超过之后就变成红黑树了)。

- 扩容上
1.7，1.8在扩容的时候，都需要新建一个之前容量*2的数组，但是1.7的每个key的值都需要重新运算hash值，而1.8扩容后的hash可以进行规律计算，极大减少了扩容的时间。另外，因为1.7采用的是头插法，在多线程中会出现逆序或者链表死循环的问题，而1.8在多线程中因为是尾插法，所以不会出现这种情况。但是，hashMap依旧是线程不安全的。

- 读取速度上
数据量大的时候快的不是一星半点，1.7最坏的打算是需要算出数组下标之后，遍历了所有的元素。而1.8之后采用红黑树，在查询、删除、更新都有极大的优势。


**Q:hashMap中的加载因子有什么用，hashMap如何扩容。**

***A：***加载因子(loadFactor)默认值是0.75(loadFactor的值允许>1)，它是给map设置一些空余空间，当loadFactor过低时，空间利用率小，但是查询效率高。当loadFactor过高时，空间利用率高，链表变长，查找效率变低。扩容阀值threshold=容量*加载因子，当容量为16，加载因子为0.75时，当map的size为13的时候就开始扩容了。

**Q:如何使Map线程安全**

***A：*** 
1. **使用HashTable:**
确实可以使用HashTable来解决线程安全的问题，而且HashTable可以看做是另一种HashMap，因为HashTable虽然没有key值，但是是根据value的值计算出hash值，进行hashMap的操作的。但是HashTable保证线程安全使用的是synchronize，那么说在put和get的时候都会将整个表进行阻塞，所以效率非常低下。
2. **Collections.synchronizedMap(map):**
   这种方法是在put，和get的时候在在外面包了一层synchronized，保证了线程安全，实现方式跟HashTable很像。
   ``` java
	public V put(K var1, V var2) {
            Object var3 = this.mutex;
            synchronized(this.mutex) {
                return this.m.put(var1, var2);
            }
        }

   ```
3. **ConcurrentHashMap:**
- 1.7：ConcurrentHashMap的实现方式与1.7的hashMap核心思想多出一个Segment数组，每个数组都是一个HashEntry<K,V>[] table，相当于一个HashMap又根据hash分成了几部分。重要的是Segment继承了可重入锁ReentrantLock，这样相当于把HashMap分成了好几个部分，这样只是落入每个槽之内的key相互竞争。在put的时候，都需要先tryLock()申请锁，如果申请锁成功了，那么进行put操作。如果没有申请到锁，就进入scanAndLockForPut()方法，再方法里一直尝试tryLock()申请锁，如果超过64次没有申请到锁，那么就上锁，等待其他线程释放锁。
注： tryLock():如果当前对象没锁，申请锁并返回ture；如果没锁，直接返回false。   

缺点：因为1.7中ConcurrentHashMap分成了多个Segment，所以算总量的时候需要多个Segment的和。因为是高并发，所以他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的；如果三次之外，将每个Segment加锁，算出结果。


``` java 
private HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {
            HashEntry<K,V> first = entryForHash(this, hash);
            HashEntry<K,V> e = first;
            HashEntry<K,V> node = null;
            int retries = -1; // negative while locating node
		//一直在尝试申请锁
            while (!tryLock()) {
                HashEntry<K,V> f; // to recheck first below
                if (retries < 0) {
                    if (e == null) {
                        if (node == null) // speculatively create node
                            node = new HashEntry<K,V>(hash, key, value, null);
                        retries = 0;
                    }
                    else if (key.equals(e.key))
                        retries = 0;
                    else
                        e = e.next;
                }
                else if (++retries > MAX_SCAN_RETRIES) {
                    //超过申请次数，上锁，等待其他线程释放锁。
                    lock();
                    break;
                }
                else if ((retries & 1) == 0 &&
                         (f = entryForHash(this, hash)) != first) {
                    e = first = f; // re-traverse if entry changed
                    retries = -1;
                }
            }
            return node;
        }

```

- 1.8 

ConcurrentHashMap在1.8中的结构与HashMap中是一样的，都是数组+链表+红黑树组合，为了更好地并发，设置了int类型的标志位，当扩容或者或是扩容的时候，然后使用CAS技术，将标志位设置为-1，其他线程获取到-1的时候，就等待；在put的时候，使用synchronize锁住对象，保证数据的安全性。

注：
	1.ConcurrentHashMap每次操作都会记录size值，而不是像1.7那样需要计算。
	2.ConcurrentHashMap构造函数是一个空方法，初始化是在put()的时候。
	3.put的时候，如果发现需要扩容，额外开启一个线程进行扩容，该线程等待map扩容，保证扩容的效率。

